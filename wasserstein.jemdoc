# jemdoc: addpackage{color}
= Wasserstein Distance (Optimal Transport Problem)

~~~
This page is currently under construction.
~~~

== Formulation

The OT problem seeks to answer this question: /How do you best move given piles of sand to fill up given holes (in another place) of the same total volume?/ Let's translate this into math (see [https://www.math.ucdavis.edu/~qlxia/Research/monge.pdf these slides]): 

- "piles of sand": a positive measure $\mu$ defined on $X$
- "holes (in another place)": another positive measure $\nu$ defined on $Y$
- "same total volume": usually we restrict $\mu$ and $\nu$ to be probability measures (so the total volume is 1)
- "best": the total cost to move should be minimized. The cost for moving 1 unit of mass from $x\in X$ to $y\in Y$ is $c(x,y)$.

Under different formulations, interpretations of the following words/phrases may differ:
- "move": transport maps (a measurable map $F$) or transport plans (probability measure $\gamma$)
- "fill up": $F_{\#}\mu = \nu$ for transport maps and $\left(\pi_X\right)_{\#} \gamma=\mu$, $\left(\pi_Y\right)_{\#} \gamma=\nu$ for transport plans.

=== Monge's formulation

Given two measure space $(X,\mu)$ and $(Y,\nu)$, we define a measurable map $F:X\to Y$ with
\(
F_{\#}\mu = \nu, \quad \text{i.e., }\; \int_{F^{-1}(A)}  \mathrm d \mu(x) = \int_A \mathrm d \nu(y) \quad \forall \text{ measurable } A\in Y.
\)
This is also known as the "pushfoward of $\mu$", or the "transport map". The Monge's formulation for the OT problem is
\(
\min_{F} \int_X c\big(x,F(x)\big) \mathrm d \mu(x),
\)
where $c:X\times Y\to \mathbb{R}^+$ is the cost of transportation. 

However, the problem is not well-posed in a sense that there may not always be a transport map for two given measures, since each particle must be moved as a whole. For example, it cannot deal with cases where numbers of particles (with positive mass) are not equal (e.g., $X=[-1,1]$, $\mu=\delta_0$, $\nu=\frac{\delta_{-1}+\delta_{1}}{2}$).

=== Kantorovich's formulation

Instead of defining the transport map, Kantorovich proposed the "transport plan" which allows particles to be split and moved to different places ("Kantorovich's relaxation"). It is a probability measure $\gamma\in X\times Y$ with marginals $\mu$ and $\nu$, i.e.,
\(
\left(\pi_X\right)_{\#} \gamma=\mu,\quad \left(\pi_Y\right)_{\#} \gamma=\nu,
\)
where $\pi_X:X\times Y\to X$ and $\pi_Y:X\times Y\to Y$ are called canonical projections. Note that there will be multiple joint distributions that correspond to the given two marginal distributions $\mu$ and $\nu$. We denote the set of all such joint distributions as $\Pi(\mu,\nu)$. The Kantorovich's formulation is
\(
    \min_{\gamma\in \Pi(\mu,\nu)}\int_{X\times Y} c(x,y)\mathrm d\gamma(x,y).
\)

Since the problem is convex, the solutions for the dual and the primal problem will be the same. So we have 
[https://en.wikipedia.org/wiki/Wasserstein_metric\#Dual_representation_of_W1 Kantorovich's dual formulation]. 

=== Relationship between these two formulations

If a transport map $F$ exists, then it will induce a unique transport plan $\gamma$ with the same cost function given by $\gamma = (\mathrm{Id},F)_{\#}\mu$. Moreover, if $F$ is the optimal transport map, $\gamma$ induced by $F$ will be the optimal transport plan. The inverse is not true: The existence of transport plans does NOT guarantee the existence of transport maps.

*Brenier's theorem*: If $X=Y=\mathbb{R}^n$, $c(x,y)=\|x-y\|^2$, $\mu,\nu$ are with finite second-order moments and $\mu$ is absolutely continuous, then there exist a unique optimal transport map $F$ and a unique optimal transport plan: 
\( \int_X\|x-F(x)\|^2 \mathrm{d} \mu(x) =  \min_{\gamma\in \Pi(\mu,\nu)}\int_{X\times Y} \|x-y\|^2\mathrm d\gamma(x,y). \) 
Moreover, $F=\nabla \phi(x)$ for some convex scalar function $\phi: \mathbb{R}^m\to \mathbb{R}$. Note that $\phi$ can be solved from the [https://en.wikipedia.org/wiki/Monge–Ampère_equation Monge-Ampère equation] 
\(
    I_0(x)=\mathrm{det}\big(\nabla^2 \phi(x)\big)I_1\big(\nabla \phi(x)\big)\quad \Longleftrightarrow \quad I_0(x)=\operatorname{det}(D F(x)) I_1(F(x))
\)
where $I_0$ and $I_1$ are density functions of $\mu$ and $\nu$ respectively, and  $DF$ is the Jacobian matrix of $F$.



== Solving the problem

For one dimensional problem with $c(x,y)=|x-y|^p$, the solution is simply given as 
\(
\left(\int_0^1\left|F_0^{-1}(z)-F_1^{-1}(z)\right|^p d z\right)^{\frac{1}{p}}
\)
where $F_0^{-1}$ and $F_1^{-1}$ are the quantile functions (inverse CDFs).

However, higher dimensional cases are more complicated and we will not have such closed form expression (except for Normal distributions).

=== Linear programming

This solver relies on discretization. Consider the densities $I_0(x)=\sum_{i=1}^{n_p}p_i\delta(x-x_i)$ and $I_1(x)=\sum_{j=1}^{n_q}q_j\delta(y-y_j)$. The problem has the following form:
\(
\begin{aligned}
\min_{\boldsymbol{\gamma}=(\gamma_{ij}) \in \mathbb{R}^{n_p\times n_q}} \quad &\sum_{i=1}^{n_p}\sum_{j=1}^{n_q} c(x_i,y_j)\gamma_{ij}\\
\text{subject to} \quad & \sum_{i=1}^{n_p} \gamma_{ij} = q_j, \quad \forall j=1,\cdots,n_q\\
 & \sum_{j=1}^{n_q} \gamma_{ij} = p_i, \quad \forall i=1,\cdots,n_p\\
 & \gamma_{ij}\geq 0, \quad \forall i,j.
\end{aligned}
\)
Corresponding MATLAB codes can be downloaded here. This method is applicable to general costs, but will have great trouble when the densities are supported on a large number of sites.

=== Gradient Descent with Brenier's theorem

The key idea of this algorithm is that $F=\nabla \phi(x)$ for some convex function $\phi: X\to \mathbb{R}$ and thus $F$ is [https://en.wikipedia.org/wiki/Curl_(mathematics)\#Identities curl-free]. The procedure begins with finding an arbitrary transport map (not necessarily optimal!), and repeating updating it so that it remains a transport map while reducing the curl and the distance. {{<font style="color:red">(Attention: transport map + curlfree $\neq$ optimal map, that's why we also need to minimize the objective function, i.e., the distance)</font>}}

==== Finding the initial transport map

In this step, we need to map two probability measures. In fact, this is closely related to [https://en.wikipedia.org/wiki/Coupling_(probability) couplings], or to be more specific, deterministic couplings (for details, see [https://cedricvillani.org/sites/dev/files/old_images/2012/08/preprint-1.pdf this book]). 

The method is called "Knothe-Rosenblatt rearrangement". It solves a family of one dimensional problems to ﬁnd the $n$-dimensional solution. _To begin with_, we compute the marginals of the first variable, which we denote by $\mu^{(1)}$ and $\nu^{(1)}$ with densities
\(
   I_0^{(1)}(x^{(1)}) =  \int_{-\infty}^{\infty} I_0(x^{(1)},x^{(2)}) \mathrm d x^{(1)}, \quad I_1^{(1)}(y^{(1)})=\int_{-\infty}^{\infty} I_1(y^{(1)},y^{(2)}) \mathrm d y^{(2)}.
\)
Then we need to consider the optimal transport map between $\mu^{(1)}$ and $\nu^{(1)}$, which is a one-dimensional problem! We denote it as $F_0^{(1)}$, then 
$(F_0^{(1)})_\# \mu^{(1)}=\nu^{(1)}$ can be written as
\(
    \int_{-\infty}^{F_0^{(1)}(x^{(1)})} I_1^{(1)}(\eta) \mathrm d \eta =  \int_{-\infty}^{x^{(1)}} I_0^{(1)}(\eta) \mathrm d \eta , \quad \text{i.e.,}\quad \int_{-\infty}^{F_0^{(1)}(x^{(1)})} \int_{-\infty}^{\infty} I_1(\eta,y^{(2)}) \mathrm d y^{(2)} \mathrm d \eta =  \int_{-\infty}^{x^{(1)}}  \int_{-\infty}^{\infty} I_0(\eta,x^{(2)}) \mathrm d x^{(2)}  \mathrm d \eta.
\)
We need to solve for $F_0^{(1)}$ via this equation.

_In the next step_, we will consider the [https://en.wikipedia.org/wiki/Disintegration_theorem disintegration] of the marginal of the first two variables (which is $\mu$ and $\nu$ in our $\mathbb{R}^2$ case) with respect to $\mu^{(1)}$ and $\nu^{(1)}$. This will give us $\mu^{(2)}(x^{(2)}|x^{(1)})$ and $\nu^{(2)}(y^{(2)}|y^{(1)})$ with densities
\(
I_0^{(2)}(x^{(2)}|x^{(1)})=\frac{I_0(x^{(1)},x^{(2)})}{I_0^{(1)}(x^{(1)})}, \quad I_1^{(2)}(y^{(2)}|y^{(1)})=\frac{I_1(y^{(1)},y^{(2)})}{I_1^{(1)}(y^{(1)})}.
\)
Similarly, we need to consider the optimal transport map between $\mu^{(2)}$ and $\nu^{(2)}$. We denote it as $F_0^{(2)}$, which can be solved through
\(
\int_{-\infty}^{F_0^{(2)}(x^{(1)}, x^{(2)})} \int_{-\infty}^{F_0^{(1)}(x^{(1)})} I_1(y^{(1)}, y^{(2)}) \mathrm d y^{(1)} \mathrm d y^{(2)}=\int_{-\infty}^{x^{(2)}} \int_{-\infty}^{x^{(1)}} I_0(\eta, \tau) \mathrm d \eta \mathrm d \tau.
\)
The _final solution_ (for $X,Y\subset \mathbb{R}^2$) is given as
\(
   \color{blue}{ F_0(x) = \begin{bmatrix}
        F_0^{(1)}(x^{(1)}) \\ F_0^{(2)}(x^{(1)},x^{(2)})
    \end{bmatrix}, \quad \text{for } x=(x^{(1)},x^{(2)})\in X. }
\)
This process can be repeated to obtain the solution in $\mathbb{R}^n$.


==== Removing the curl

After the initial map is found, we need to remove its curl. This is not completed in one run. Instead, we consider the map $S:X\to X$ with $S_{\#}\mu=\mu$ ("measure preserving"). This map is parametrized by time $t$, so that it becomes a "flow" and will be updated as time progresses.  The map is initiated as the identity $S(x,0)=x$, and the final goal is to let $F_0(S^{-1}(x,t))$ converge to a curl-free mapping.

Noe let's focus only on decreasing the objective function $M$, namely
\(
    M(t) = \int_{X}\|F(x, t)-x\|^2 I_0(x) \mathrm d x
\)
We take the derivative wrt. $t$ (for details, see \[[https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97 2]\]):
\(
    \frac{\partial M}{\partial t}=-2 \int_{X}\left\langle F(x, t), I_0(\color{green}{\frac{\partial S}{\partial t} \circ S^{-1}(x, t)})\right\rangle \mathrm d x
\)
The question is, what is $\frac{\partial S}{\partial t}$. Recall that $S$ should preserve the measure, i.e., $ I_0(x)=\operatorname{det}(D S(x)) I_0(S(x))$. By differentiating this equation, we have
\(
\begin{equation}
\color{green}{\frac{\partial S}{\partial t}} = (\frac{1}{I_0}\xi)\color{green}{\circ S},
\label{eq:AHT-S}
\end{equation}
\) 
for some divergence-free vector field $\xi$ on $X$ so that $\langle \xi,\mathbf{n}\rangle=0$ with $\mathbf{n}$ being normal to the boundary of $X$. Subsequently, we have
\(
\frac{\partial M}{\partial t}=-2 \int_{X}\bigg\langle F(x, t), \xi(x, t)\bigg\rangle \mathrm d x.
\)
Notice that $\xi$ is divergence-free, and that by [https://en.wikipedia.org/wiki/Helmholtz_decomposition Helmholtz decomposition] $F=\nabla \phi+\chi$ for divergence-free field $\chi$. Using the [https://en.wikipedia.org/wiki/Divergence_theorem divergence theorem], we can simplify the above equation
\(
\frac{\partial M}{\partial t}=-2 \int_{X}\bigg\langle \chi(x, t), \xi(x, t)\bigg\rangle \mathrm d x.
\)
Now we see that if we take $\xi=\chi$, then $M$ will decrease most. But how do we find $\chi$? One way is to first find $\phi$ and then subtract $\nabla \phi$ from $F$, since finding $\phi$ is much simpler. Using the fact that $\chi$ is divergence-free, we take the divergence of both sides in the Helmholtz decomposition, and will have
\(
\operatorname{div}(F)=\Delta \phi,
\)
with boundary condition $\langle\nabla \phi, \mathbf{n}\rangle=\langle F, \mathbf{n}\rangle$ on $\partial X$. We simply write the solution for this equation as
\(
\phi = \Delta^{-1}\operatorname{div}(F),
\)
and thus $\xi=\chi = F-\nabla \Delta^{-1}\operatorname{div}(F)$. Now, at this stage, we can precisely characterize $S$ through $\eqref{eq:AHT-S}$. As a consequence, through $F(x, t)=F_0\left(S^{-1}(x, t)\right)$, we can also characterize $F$, by
\(
\frac{\partial F}{\partial t} = -\frac{1}{I_0}(DF)\xi \implies \frac{\partial F}{\partial t} =-\frac{1}{I_0}(DF)( F-\nabla \Delta^{-1}\operatorname{div}(F)).
\)
Now, this equation can be translated into the numerical scheme as 
\(
\color{blue}{F(x,t_{n+1}) = F(x,t_n) + \alpha \frac{1}{I_0}(DF)( F-\nabla \Delta^{-1}\operatorname{div}(F(x,t_n))).}
\)
Note that there will be simpler expression in $\mathbb{R}^2$ (see \[[https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97 2]\]).



=== Gradient Descent with Kantorovich's dual formulation


== Applications






== References and further readings

# Nicolas Bonnotte. From knothe’s rearrangement to brenier’s optimal transport map. SIAM Journal on Mathematical Analysis, 45(1):64–87, 2013.
. Cedric Villani. [https://cedricvillani.org/sites/dev/files/old_images/2012/08/preprint-1.pdf Optimal transport: old and new], volume 338. Springer Science & Business Media, 2008.
. Steven Haker, Lei Zhu, Allen Tannenbaum, and Sigurd Angenent. [https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97 Optimal mass transport for registration and warping.] International Journal of Computer Vision, 60(3):225–240, 2004.







