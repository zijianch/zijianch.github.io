<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Wasserstein Distance (Optimal Transport Problem)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Wasserstein Distance (Optimal Transport Problem)</h1>
</div>
<div class="infoblock">
<div class="blockcontent">
<p>This page is currently under construction.
</p>
</div></div>
<h2>Formulation</h2>
<p>The OT problem seeks to answer this question: <i>How do you best move given piles of sand to fill up given holes (in another place) of the same total volume?</i> Let's translate this into math (see <a href="https://www.math.ucdavis.edu/~qlxia/Research/monge.pdf" target=&ldquo;blank&rdquo;>these slides</a>): 
</p>
<ul>
<li><p>&ldquo;piles of sand&rdquo;: a positive measure \(\mu\) defined on \(X\)
</p>
</li>
<li><p>&ldquo;holes (in another place)&rdquo;: another positive measure \(\nu\) defined on \(Y\)
</p>
</li>
<li><p>&ldquo;same total volume&rdquo;: usually we restrict \(\mu\) and \(\nu\) to be probability measures (so the total volume is 1)
</p>
</li>
<li><p>&ldquo;best&rdquo;: the total cost to move should be minimized. The cost for moving 1 unit of mass from \(x\in X\) to \(y\in Y\) is \(c(x,y)\).
</p>
</li>
</ul>
<p>Under different formulations, interpretations of the following words/phrases may differ:
</p>
<ul>
<li><p>&ldquo;move&rdquo;: transport maps (a measurable map \(F\)) or transport plans (probability measure \(\gamma\))
</p>
</li>
<li><p>&ldquo;fill up&rdquo;: \(F_{\#}\mu = \nu\) for transport maps and \(\left(\pi_X\right)_{\#} \gamma=\mu\), \(\left(\pi_Y\right)_{\#} \gamma=\nu\) for transport plans.
</p>
</li>
</ul>
<h3>Monge's formulation</h3>
<p>Given two measure space \((X,\mu)\) and \((Y,\nu)\), we define a measurable map \(F:X\to Y\) with
</p>
<p style="text-align:center">
\[
F_{\#}\mu = \nu, \quad \text{i.e., }\; \int_{F^{-1}(A)}  \mathrm d \mu(x) = \int_A \mathrm d \nu(y) \quad \forall \text{ measurable } A\in Y.
\]
</p><p>This is also known as the &ldquo;pushfoward of \(\mu\)&rdquo;, or the &ldquo;transport map&rdquo;. The Monge's formulation for the OT problem is
</p>
<p style="text-align:center">
\[
\min_{F} \int_X c\big(x,F(x)\big) \mathrm d \mu(x),
\]
</p><p>where \(c:X\times Y\to \mathbb{R}^+\) is the cost of transportation. 
</p>
<p>However, the problem is not well-posed in a sense that there may not always be a transport map for two given measures, since each particle must be moved as a whole. For example, it cannot deal with cases where numbers of particles (with positive mass) are not equal (e.g., \(X=[-1,1]\), \(\mu=\delta_0\), \(\nu=\frac{\delta_{-1}+\delta_{1}}{2}\)).
</p>
<h3>Kantorovich's formulation</h3>
<p>Instead of defining the transport map, Kantorovich proposed the &ldquo;transport plan&rdquo; which allows particles to be split and moved to different places (&ldquo;Kantorovich's relaxation&rdquo;). It is a probability measure \(\gamma\in X\times Y\) with marginals \(\mu\) and \(\nu\), i.e.,
</p>
<p style="text-align:center">
\[
\left(\pi_X\right)_{\#} \gamma=\mu,\quad \left(\pi_Y\right)_{\#} \gamma=\nu,
\]
</p><p>where \(\pi_X:X\times Y\to X\) and \(\pi_Y:X\times Y\to Y\) are called canonical projections. Note that there will be multiple joint distributions that correspond to the given two marginal distributions \(\mu\) and \(\nu\). We denote the set of all such joint distributions as \(\Pi(\mu,\nu)\). The Kantorovich's formulation is
</p>
<p style="text-align:center">
\[
    \min_{\gamma\in \Pi(\mu,\nu)}\int_{X\times Y} c(x,y)\mathrm d\gamma(x,y).
\]
</p><p>Since the problem is convex, the solutions for the dual and the primal problem will be the same. So we have 
<a href="https://en.wikipedia.org/wiki/Wasserstein_metric#Dual_representation_of_W1" target=&ldquo;blank&rdquo;>Kantorovich's dual formulation</a>. 
</p>
<h3>Relationship between these two formulations</h3>
<p>If a transport map \(F\) exists, then it will induce a unique transport plan \(\gamma\) with the same cost function given by \(\gamma = (\mathrm{Id},F)_{\#}\mu\). Moreover, if \(F\) is the optimal transport map, \(\gamma\) induced by \(F\) will be the optimal transport plan. The inverse is not true: The existence of transport plans does NOT guarantee the existence of transport maps.
</p>
<p><b>Brenier's theorem</b>: If \(X=Y=\mathbb{R}^n\), \(c(x,y)=\|x-y\|^2\), \(\mu,\nu\) are with finite second-order moments and \(\mu\) is absolutely continuous, then there exist a unique optimal transport map \(F\) and a unique optimal transport plan: 
</p>
<p style="text-align:center">
\[ \int_X\|x-F(x)\|^2 \mathrm{d} \mu(x) =  \min_{\gamma\in \Pi(\mu,\nu)}\int_{X\times Y} \|x-y\|^2\mathrm d\gamma(x,y). \]
</p><p>Moreover, \(F=\nabla \phi(x)\) for some convex scalar function \(\phi: \mathbb{R}^m\to \mathbb{R}\). Note that \(\phi\) can be solved from the <a href="https://en.wikipedia.org/wiki/Monge–Ampère_equation" target=&ldquo;blank&rdquo;>Monge-Ampère equation</a> 
</p>
<p style="text-align:center">
\[
    I_0(x)=\mathrm{det}\big(\nabla^2 \phi(x)\big)I_1\big(\nabla \phi(x)\big)\quad \Longleftrightarrow \quad I_0(x)=\operatorname{det}(D F(x)) I_1(F(x))
\]
</p><p>where \(I_0\) and \(I_1\) are density functions of \(\mu\) and \(\nu\) respectively, and  \(DF\) is the Jacobian matrix of \(F\).
</p>
<h2>Solving the problem</h2>
<p>For one dimensional problem with \(c(x,y)=|x-y|^p\), the solution is simply given as 
</p>
<p style="text-align:center">
\[
\left(\int_0^1\left|F_0^{-1}(z)-F_1^{-1}(z)\right|^p d z\right)^{\frac{1}{p}}
\]
</p><p>where \(F_0^{-1}\) and \(F_1^{-1}\) are the quantile functions (inverse CDFs).
</p>
<p>However, higher dimensional cases are more complicated and we will not have such closed form expression (except for Normal distributions).
</p>
<h3>Linear programming</h3>
<p>This solver relies on discretization. Consider the densities \(I_0(x)=\sum_{i=1}^{n_p}p_i\delta(x-x_i)\) and \(I_1(x)=\sum_{j=1}^{n_q}q_j\delta(y-y_j)\). The problem has the following form:
</p>
<p style="text-align:center">
\[
\begin{aligned}
\min_{\boldsymbol{\gamma}=(\gamma_{ij}) \in \mathbb{R}^{n_p\times n_q}} \quad &amp;\sum_{i=1}^{n_p}\sum_{j=1}^{n_q} c(x_i,y_j)\gamma_{ij}\\
\text{subject to} \quad &amp; \sum_{i=1}^{n_p} \gamma_{ij} = q_j, \quad \forall j=1,\cdots,n_q\\
 &amp; \sum_{j=1}^{n_q} \gamma_{ij} = p_i, \quad \forall i=1,\cdots,n_p\\
 &amp; \gamma_{ij}\geq 0, \quad \forall i,j.
\end{aligned}
\]
</p><p>Corresponding MATLAB codes can be downloaded here. This method is applicable to general costs, but will have great trouble when the densities are supported on a large number of sites.
</p>
<h3>Gradient Descent with Brenier's theorem</h3>
<p>The key idea of this algorithm is that \(F=\nabla \phi(x)\) for some convex function \(\phi: X\to \mathbb{R}\) and thus \(F\) is <a href="https://en.wikipedia.org/wiki/Curl_(mathematics)#Identities" target=&ldquo;blank&rdquo;>curl-free</a>. The procedure begins with finding an arbitrary transport map (not necessarily optimal!), and repeating updating it so that it remains a transport map while reducing the curl and the distance. <font style="color:red">(Attention: transport map + curlfree \(\neq\) optimal map, that's why we also need to minimize the objective function, i.e., the distance)</font>
</p>
<h4>Finding the initial transport map</h4>
<p>In this step, we need to map two probability measures. In fact, this is closely related to <a href="https://en.wikipedia.org/wiki/Coupling_(probability)" target=&ldquo;blank&rdquo;>couplings</a>, or to be more specific, deterministic couplings (for details, see <a href="https://cedricvillani.org/sites/dev/files/old_images/2012/08/preprint-1.pdf" target=&ldquo;blank&rdquo;>this book</a>). 
</p>
<p>The method is called &ldquo;Knothe-Rosenblatt rearrangement&rdquo;. It solves a family of one dimensional problems to ﬁnd the \(n\)-dimensional solution. <u>To begin with</u>, we compute the marginals of the first variable, which we denote by \(\mu^{(1)}\) and \(\nu^{(1)}\) with densities
</p>
<p style="text-align:center">
\[
   I_0^{(1)}(x^{(1)}) =  \int_{-\infty}^{\infty} I_0(x^{(1)},x^{(2)}) \mathrm d x^{(1)}, \quad I_1^{(1)}(y^{(1)})=\int_{-\infty}^{\infty} I_1(y^{(1)},y^{(2)}) \mathrm d y^{(2)}.
\]
</p><p>Then we need to consider the optimal transport map between \(\mu^{(1)}\) and \(\nu^{(1)}\), which is a one-dimensional problem! We denote it as \(F_0^{(1)}\), then 
\((F_0^{(1)})_\# \mu^{(1)}=\nu^{(1)}\) can be written as
</p>
<p style="text-align:center">
\[
    \int_{-\infty}^{F_0^{(1)}(x^{(1)})} I_1^{(1)}(\eta) \mathrm d \eta =  \int_{-\infty}^{x^{(1)}} I_0^{(1)}(\eta) \mathrm d \eta , \quad \text{i.e.,}\quad \int_{-\infty}^{F_0^{(1)}(x^{(1)})} \int_{-\infty}^{\infty} I_1(\eta,y^{(2)}) \mathrm d y^{(2)} \mathrm d \eta =  \int_{-\infty}^{x^{(1)}}  \int_{-\infty}^{\infty} I_0(\eta,x^{(2)}) \mathrm d x^{(2)}  \mathrm d \eta.
\]
</p><p>We need to solve for \(F_0^{(1)}\) via this equation.
</p>
<p><u>In the next step</u>, we will consider the <a href="https://en.wikipedia.org/wiki/Disintegration_theorem" target=&ldquo;blank&rdquo;>disintegration</a> of the marginal of the first two variables (which is \(\mu\) and \(\nu\) in our \(\mathbb{R}^2\) case) with respect to \(\mu^{(1)}\) and \(\nu^{(1)}\). This will give us \(\mu^{(2)}(x^{(2)}|x^{(1)})\) and \(\nu^{(2)}(y^{(2)}|y^{(1)})\) with densities
</p>
<p style="text-align:center">
\[
I_0^{(2)}(x^{(2)}|x^{(1)})=\frac{I_0(x^{(1)},x^{(2)})}{I_0^{(1)}(x^{(1)})}, \quad I_1^{(2)}(y^{(2)}|y^{(1)})=\frac{I_1(y^{(1)},y^{(2)})}{I_1^{(1)}(y^{(1)})}.
\]
</p><p>Similarly, we need to consider the optimal transport map between \(\mu^{(2)}\) and \(\nu^{(2)}\). We denote it as \(F_0^{(2)}\), which can be solved through
</p>
<p style="text-align:center">
\[
\int_{-\infty}^{F_0^{(2)}(x^{(1)}, x^{(2)})} \int_{-\infty}^{F_0^{(1)}(x^{(1)})} I_1(y^{(1)}, y^{(2)}) \mathrm d y^{(1)} \mathrm d y^{(2)}=\int_{-\infty}^{x^{(2)}} \int_{-\infty}^{x^{(1)}} I_0(\eta, \tau) \mathrm d \eta \mathrm d \tau.
\]
</p><p>The <u>final solution</u> (for \(X,Y\subset \mathbb{R}^2\)) is given as
</p>
<p style="text-align:center">
\[
   \color{blue}{ F_0(x) = \begin{bmatrix}
        F_0^{(1)}(x^{(1)}) \\ F_0^{(2)}(x^{(1)},x^{(2)})
    \end{bmatrix}, \quad \text{for } x=(x^{(1)},x^{(2)})\in X. }
\]
</p><p>This process can be repeated to obtain the solution in \(\mathbb{R}^n\).
</p>
<h4>Removing the curl</h4>
<p>After the initial map is found, we need to remove its curl. This is not completed in one run. Instead, we consider the map \(S:X\to X\) with \(S_{\#}\mu=\mu\) (&ldquo;measure preserving&rdquo;). This map is parametrized by time \(t\), so that it becomes a &ldquo;flow&rdquo; and will be updated as time progresses.  The map is initiated as the identity \(S(x,0)=x\), and the final goal is to let \(F_0(S^{-1}(x,t))\) converge to a curl-free mapping.
</p>
<p>Noe let's focus only on decreasing the objective function \(M\), namely
</p>
<p style="text-align:center">
\[
    M(t) = \int_{X}\|F(x, t)-x\|^2 I_0(x) \mathrm d x
\]
</p><p>We take the derivative wrt. \(t\) (for details, see [<a href="https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97" target=&ldquo;blank&rdquo;>2</a>]):
</p>
<p style="text-align:center">
\[
    \frac{\partial M}{\partial t}=-2 \int_{X}\left\langle F(x, t), I_0(\color{green}{\frac{\partial S}{\partial t} \circ S^{-1}(x, t)})\right\rangle \mathrm d x
\]
</p><p>The question is, what is \(\frac{\partial S}{\partial t}\). Recall that \(S\) should preserve the measure, i.e., \( I_0(x)=\operatorname{det}(D S(x)) I_0(S(x))\). By differentiating this equation, we have
</p>
<p style="text-align:center">
\[
\begin{equation}
\color{green}{\frac{\partial S}{\partial t}} = (\frac{1}{I_0}\xi)\color{green}{\circ S},
\label{eq:AHT-S}
\end{equation}
\]
</p><p>for some divergence-free vector field \(\xi\) on \(X\) so that \(\langle \xi,\mathbf{n}\rangle=0\) with \(\mathbf{n}\) being normal to the boundary of \(X\). Subsequently, we have
</p>
<p style="text-align:center">
\[
\frac{\partial M}{\partial t}=-2 \int_{X}\bigg\langle F(x, t), \xi(x, t)\bigg\rangle \mathrm d x.
\]
</p><p>Notice that \(\xi\) is divergence-free, and that by <a href="https://en.wikipedia.org/wiki/Helmholtz_decomposition" target=&ldquo;blank&rdquo;>Helmholtz decomposition</a> \(F=\nabla \phi+\chi\) for divergence-free field \(\chi\). Using the <a href="https://en.wikipedia.org/wiki/Divergence_theorem" target=&ldquo;blank&rdquo;>divergence theorem</a>, we can simplify the above equation
</p>
<p style="text-align:center">
\[
\frac{\partial M}{\partial t}=-2 \int_{X}\bigg\langle \chi(x, t), \xi(x, t)\bigg\rangle \mathrm d x.
\]
</p><p>Now we see that if we take \(\xi=\chi\), then \(M\) will decrease most. But how do we find \(\chi\)? One way is to first find \(\phi\) and then subtract \(\nabla \phi\) from \(F\), since finding \(\phi\) is much simpler. Using the fact that \(\chi\) is divergence-free, we take the divergence of both sides in the Helmholtz decomposition, and will have
</p>
<p style="text-align:center">
\[
\operatorname{div}(F)=\Delta \phi,
\]
</p><p>with boundary condition \(\langle\nabla \phi, \mathbf{n}\rangle=\langle F, \mathbf{n}\rangle\) on \(\partial X\). We simply write the solution for this equation as
</p>
<p style="text-align:center">
\[
\phi = \Delta^{-1}\operatorname{div}(F),
\]
</p><p>and thus \(\xi=\chi = F-\nabla \Delta^{-1}\operatorname{div}(F)\). Now, at this stage, we can precisely characterize \(S\) through \(\eqref{eq:AHT-S}\). As a consequence, through \(F(x, t)=F_0\left(S^{-1}(x, t)\right)\), we can also characterize \(F\), by
</p>
<p style="text-align:center">
\[
\frac{\partial F}{\partial t} = -\frac{1}{I_0}(DF)\xi \implies \frac{\partial F}{\partial t} =-\frac{1}{I_0}(DF)( F-\nabla \Delta^{-1}\operatorname{div}(F)).
\]
</p><p>Now, this equation can be translated into the numerical scheme as 
</p>
<p style="text-align:center">
\[
\color{blue}{F(x,t_{n+1}) = F(x,t_n) + \alpha \frac{1}{I_0}(DF)( F-\nabla \Delta^{-1}\operatorname{div}(F(x,t_n))).}
\]
</p><p>Note that there will be simpler expression in \(\mathbb{R}^2\) (see [<a href="https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97" target=&ldquo;blank&rdquo;>2</a>]).
</p>
<h3>Gradient Descent with Kantorovich's dual formulation</h3>
<h2>Applications</h2>
<h2>References and further readings</h2>
<ol>
<li><p>Cedric Villani. <a href="https://cedricvillani.org/sites/dev/files/old_images/2012/08/preprint-1.pdf" target=&ldquo;blank&rdquo;>Optimal transport: old and new</a>, volume 338. Springer Science &amp; Business Media, 2008.
</p>
</li>
<li><p>Steven Haker, Lei Zhu, Allen Tannenbaum, and Sigurd Angenent. <a href="https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97" target=&ldquo;blank&rdquo;>Optimal mass transport for registration and warping.</a> International Journal of Computer Vision, 60(3):225–240, 2004.
</p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2022-12-22 22:03:07 CST.
</div>
</div>
</div>
</body>
</html>
