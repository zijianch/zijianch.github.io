<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>HCP dataset</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-252546838-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="sws_intro.html">Intro</a></div>
<div class="menu-item"><a href="index.html">Homepage</a></div>
<div class="menu-category">Software</div>
<div class="menu-item"><a href="freesurfer.html">FreeSurfer</a></div>
<div class="menu-item"><a href="ants.html">ANTs</a></div>
<div class="menu-item"><a href="MRtrix.html">MRtrix</a></div>
<div class="menu-item"><a href="afni.html">AFNI</a></div>
<div class="menu-item"><a href="FSL.html">FSL</a></div>
<div class="menu-category">Data</div>
<div class="menu-item"><a href="dataOverview.html">Overview</a></div>
<div class="menu-item"><a href="HCP.html" class="current">HCP</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>HCP dataset</h1>
</div>
<h2>Accessing HCP data</h2>
<p>Go to <a href="https://db.humanconnectome.org/app/template/Login.vm" target=&ldquo;blank&rdquo;>connectome db</a> for downloading the data. For details, see <a href="https://www.humanconnectome.org/storage/app/media/documentation/s1200/HCP_S1200_Release_Reference_Manual.pdf" target=&ldquo;blank&rdquo;>Reference Manual</a> chapter
1.
</p>
<p>For example, if you want to download the data for a specific subject, see the following steps:
</p>
<table class="imgtable"><tr><td>
<img src="./figs/HCP_download_1.png" alt="" width="50%" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>For batch downloading, use &ldquo;filters&rdquo;:
</p>
<table class="imgtable"><tr><td>
<img src="./figs/HCP_download_2.png" alt="" width="30%" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>File directory structure</h2>
<p>See <a href="https://www.humanconnectome.org/storage/app/media/documentation/s1200/HCP_S1200_Release_Reference_Manual.pdf" target=&ldquo;blank&rdquo;>Reference Manual</a> chapter 3 or <a href="https://www.humanconnectome.org/storage/app/media/documentation/s1200/HCP_S1200_Release_Appendix_III.pdf" target=&ldquo;blank&rdquo;>Appendix III</a> of the Reference Manual for more detailed information.
</p>
<p>For unprocessed images, the folders for one subject should look like the following:
</p>
<table class="imgtable"><tr><td>
<img src="./figs/HCP_dataStruct_unproc.png" alt="" width="50%" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>For preprocessed data:
</p>
<ul>
<li><p>structural
</p>
<ul>
<li><p><b> T1w/ </b>: T1w and T2w volume data (see <a href="freesurfer.html" target=&ldquo;blank&rdquo;>FreeSurfer naming conventions</a>)
</p>
<ul>
<li><p><b>T1w/Native/</b>: FreeSurfer surfaces in their native mesh and original dimensions after rigid-body rotation to AC-PC alignment.
</p>
</li></ul>
</li>
<li><p><b>MNINonLinear/</b>: data registered to MNI152 space
</p>
<ul>
<li><p><b>MNINonLinear/Native/</b>: additional files used during surface-based registration.
</p>
</li>
<li><p><b>MNINonLinear/xfms/</b>: files encoding the transformation between acpc and MNINonLinear volumetric space.
</p>
</li>
<li><p><b>MNINonLinear/fsaverage_LR32k/</b>: files spatially downsampled to a 32k mesh (average vertex spacing of 2 mm)
</p>
</li></ul>
</li></ul>
</li>
<li><p>fMRI
</p>
<ul>
<li><p><b>MNINonLinear/Results/</b> : volumetric and CIFTI grayordinates data, motion parameters, and physiological data
</p>
<ul>
<li><p>For rs-fMRI, there are 4 subdirectories named similar to <tt>rfMRI_REST1_RL</tt>
</p>
</li>
<li><p>For t-fMRI, there are 7 pairs of tfMRI scans (14 folders), named similar to <tt>tfMRI_EMOTION_RL</tt>. There are additional 7 folders named similar to <tt>tfMRI_LANGUAGE</tt> that contain an <tt>.fsf</tt> file that can be used to run analysis across the two runs of each task.
</p>
</li>
<li><p>Each of the directories contains an <tt>.fsf</tt> file and a “EVs” directory containing explanatory variables. These files can be used to run first-level analyses in the <a href="FSL.html" target=&ldquo;blank&rdquo;>FSL</a> program FEAT.
</p>
</li></ul>
</li>
<li><p>Estimates of motion parameters are saved into two different files: <tt>Movement_Regressors.txt</tt> and <tt>Movement_Regressors_dt.txt</tt>.
</p>
</li></ul>
</li>
<li><p>Diffusion
</p>
<ul>
<li><p><b> T1w/ </b>: contains <tt>T1w_acpc_dc_restore_1.25.nii.gz</tt> (structural volume)
</p>
<ul>
<li><p><b>T1w/Diffusion/</b>: contains bval, bvec, <tt>data.nii.gz</tt>(preprocessed diffusion time series), <tt>nodif_brain_mask.nii.gz</tt>(brain mask) and <tt>grad_dev.nii.gz</tt> (effects of gradient nonlinearities on the bvals and bvecs for each voxel).
</p>
</li>
</ul>

</li>
</ul>

</li>
</ul>
<h2>Basic info for the HCP data</h2>
<h3>Imaging protocols for raw data</h3>
<p><b>T1w/T2w</b>: (Chapter 2 at Page 35)
</p>
<table class="imgtable"><tr><td>
<img src="./figs/HCP_structural_protocol.png" alt="" width="30%" />&nbsp;</td>
<td align="left"></td></tr></table>
<p><b>rs-fMRI</b>: (Chapter 2 at Page 35-36)
</p>
<table class="imgtable"><tr><td>
<img src="./figs/HCP_rsfmri_protocol.png" alt="" width="30%" />&nbsp;</td>
<td align="left"></td></tr></table>
<h3>Preprocessing operations</h3>
<p><b>fMRI</b>: there are two pipelines (cf. Chapter 5 at Page 131-132):
</p>
<ul>
<li><p>fMRIVolume: spatial distortion removal, motion correction, bias field reduction, registration to the structural MNI template, and data masking with the brain mask based on FreeSurfer segmentation. (other sources of reference: [<a href="https://pubmed.ncbi.nlm.nih.gov/23668970/" target=&ldquo;blank&rdquo;>1</a>], [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7739896/" target=&ldquo;blank&rdquo;>2</a>])
</p>
</li>
<li><p>fMRISurface: aim to bring the time-series from the volume into the CIFTI grayordinates standard space. (you can ignore this) 
</p>
</li>
</ul>
<h2>Next steps&hellip;</h2>
<p>There are some of the files that we may be specifically interested in using. The section briefly introduce how to locate and use them.
</p>
<h3>T1WI</h3>
<p>File located at
</p>
<div class="codeblock">
<div class="blockcontent"><pre>
&lt;subject id&gt;/MNINonLinear/T1w.nii.gz
</pre></div></div>
<h3>rs-fMRI</h3>
<p>File located at
</p>
<div class="codeblock">
<div class="blockcontent"><pre>
&lt;subject id&gt;/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz
</pre></div></div>
<p>There are four such files (2 sessions, each session has both LR and RL). Just pick any one of them. The nii.gz file size should be around 1 GB. 
</p>
<p>This particular image is preprocessed using fMRIVolume only (see above). The resulting volumetric data contains values at \(91 \times  109 \times  91 = 902629\) 2-mm isotropic voxels (MNI152) at 1200 time points. To see this, simply download the MATLAB function <a href="https://www.mathworks.com/matlabcentral/fileexchange/8797-tools-for-nifti-and-analyze-image" target=&ldquo;blank&rdquo;>load_nii</a> and run
</p>
<div class="codeblock">
<div class="blockcontent"><pre>
nii = load_nii('rfMRI_REST1_LR.nii');
X = nii.img;
size(X)       % 91x109x91x1200 4-D single
</pre></div></div>
<p>Ultimately, we want to compute functional connectivity between each pair of ROIs. The first step is to compute the average time-series across all voxels within every single ROI. MATLAB scripting will be hard wrt atlas and registration. Instead, this can be done using:
</p>
<ul>
<li><p><a href="https://nideconv.readthedocs.io/en/latest/auto_examples/extract_timeseries_fmriprep.html" target=&ldquo;blank&rdquo;>nilearn</a>
</p>
</li>
<li><p><a href="FSL.html" target=&ldquo;blank&rdquo;>FSL</a>: can process one ROI only with <tt>fslmeants</tt>. Need to write script to automate the process for outputting all ROI time series.
</p>
</li>
</ul>
<p>And then Pearson correlation can be computed on these time-series to obtain the connectivity matrix. There are also softwares that directly output the final connectivity:
</p>
<ul>
<li><p>CONN: <a href="https://web.conn-toolbox.org/fmri-methods/connectivity-measures/roi-to-roi" target=&ldquo;blank&rdquo;>ROI-to-ROI analyses</a>, see also <a href="https://www.nitrc.org/forum/message.php?msg_id=11244" target=&ldquo;blank&rdquo;>this page</a>
</p>
</li>
</ul>
<h3>t-fMRI</h3>
<p>We use language for example. File is located at
</p>
<div class="codeblock">
<div class="blockcontent"><pre>
&lt;subject id&gt;/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz
</pre></div></div>
<h3>Diffusion</h3>
<p>File located at
</p>
<div id="footer">
<div id="footer-text">
Page generated 2023-09-24 10:52:44 EDT.
</div>
</div>
</td>
</tr>
</table>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EZMPZ1N19T"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-EZMPZ1N19T');
</script>
</body>
</html>
